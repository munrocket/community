# Title of RFC

| Status        | (Proposed)                                           |
:-------------- |:---------------------------------------------------- |
| **RFC #**     | [190](https://github.com/tensorflow/community/issues/190)|
| **Author(s)** | Munrocket (munrocket@pm.me)                          |
| **Sponsor**   | *become my sponsor*                                  |
| **Updated**   | 2019-12-18                                           |

## Objective

WebGL backend with emulated float64 precision

## Motivation

TFJS have issues with precision [1110](https://github.com/tensorflow/tfjs/issues/1110),
[1209](https://github.com/tensorflow/tfjs/issues/1209)
and [so on](https://github.com/tensorflow/tfjs/search?p=1&q=precision&type=Issues).
WASÐœ can be used for flaot64 calculations, but WASM loads CPU and not use power of GPU parallelism.

## User Benefit

Better precision for training model on PC when you release final version or even in runtime on mobile phones.
GPU implementation usually much faster on PCs and consume less power on mobile phones.

## Design Proposal

Make a [double-word](https://github.com/munrocket/double.js) implementation with float32 on GPU.
Final mantissa size will be equal to 2 x 22 = 44 bits in emulated float64, while in float64 - 52 bits.
If devices have troubles with float32 correctness we probably need to have a fallback to core webgl implementation.

### Alternatives Considered
* WASM implementation
* quad-word arithmetic
* FMA can improve double-word multiplication performance in x8.5, but it supported only on CUDA (compute 2.0 or greater)

### Performance Implications
* Slower that core implementation in ~10 times [according](http://blog.hvidtfeldts.net/index.php/2012/07/double-precision-in-opengl-and-webgl/) to mandelbrot benchmark.
* ~~Microbenchmarks not provided~~

### Dependencies
* Dependencies: none
* Dependent projects: none

### Engineering Impact
* For better maintaining, this implementation can be autogenerated from core implementation in future.
* Backward compatability in runtime on mobile phones will increase bundle size in two times.

## Questions and Discussion Topics
* Will this work on different mobile phones at all? This question need feedback from others or proper testing.
* Do we need emulated float128 with double-double technique? Somebody need higher than double precision?
